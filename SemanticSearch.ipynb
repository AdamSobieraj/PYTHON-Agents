{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Settings\n",
    "APIKey = ''\n",
    "\n",
    "import openai\n",
    "openai.api_key = APIKey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knowledge base\n",
    "knowledgebase_1 = [\n",
    "    \"Art. 11. 1. Pieszy jest obowiązany korzystać z chodnika lub drogi dla pieszych, a w razie ich braku – z pobocza. Jeżeli nie ma pobocza lub czasowo nie można z niego korzystać, pieszy może korzystać z jezdni, pod warunkiem zajmowania miejsca jak najbliżej jej krawędzi i ustępowania miejsca nadjeżdżającemu pojazdowi.\",\n",
    "    \"Art. 11. 2. Pieszy idący po poboczu lub jezdni jest obowiązany iść lewą stroną drogi.\",\n",
    "    \"Art. 11. 3. Piesi idący jezdnią są obowiązani iść jeden za drugim. Na drodze o małym ruchu, w warunkach dobrej widoczności, dwóch pieszych może iść obok siebie.\",\n",
    "    \"Art. 11. 4. Korzystanie przez pieszego z drogi dla rowerów jest dozwolone tylko w razie braku chodnika lub pobocza albo niemożności korzystania z nich. Pieszy, z wyjątkiem osoby niepełnosprawnej, korzystając z tej drogi, jest obowiązany ustąpić miejsca rowerowi.\",\n",
    "    \"Art. 11. 4a. Pieszy poruszający się po drodze po zmierzchu poza obszarem zabudowanym jest obowiązany używać elementów odblaskowych w sposób widoczny dla innych uczestników ruchu, chyba że porusza się po drodze przeznaczonej wyłącznie dla pieszych lub po chodniku.\",\n",
    "    \"Art. 11. 5. Przepisów ust. 1–4a nie stosuje się w strefie zamieszkania. W strefie tej pieszy korzysta z całej szerokości drogi i ma pierwszeństwo przed pojazdem.\",\n",
    "    \"Art. 12. 1. Kolumna pieszych, z wyjątkiem pieszych w wieku do 10 lat, może się poruszać tylko prawą stroną jezdni.\",\n",
    "    \"Art. 12. 2. Do kolumny pieszych w wieku do 10 lat stosuje się odpowiednio przepisy art. 11 ust. 1 i 2.\",\n",
    "    \"Art. 12. 3. Liczba pieszych idących jezdnią w kolumnie obok siebie nie może przekraczać 4, a w kolumnie wojskowej – 6, pod warunkiem że kolumna nie zajmuje więcej niż połowy szerokości jezdni.\",\n",
    "    \"Art. 12. 4. Piesi w wieku do 10 lat mogą iść w kolumnie tylko dwójkami pod nadzorem co najmniej jednej osoby pełnoletniej.\",\n",
    "    \"Art. 12. 5. Długość kolumny pieszych nie może przekraczać 50 m. Odległość między kolumnami nie może być mniejsza niż 100 m.\",\n",
    "    \"Art. 12. 6. Jeżeli przemarsz kolumny pieszych odbywa się w warunkach niedostatecznej widoczności: pierwszy i ostatni z idących z lewej strony są obowiązani nieść latarki: pierwszy – ze światłem białym, skierowanym do przodu, ostatni – ze światłem czerwonym, skierowanym do tyłu; w kolumnie o długości przekraczającej 20 m idący po lewej stronie z przodu i z tyłu są obowiązani używać elementów odblaskowych odpowiadających właściwym warunkom technicznym, a ponadto idący po lewej stronie są obowiązani nieść dodatkowe latarki ze światłem białym, rozmieszczone w taki sposób, aby odległość między nimi nie przekraczała 10 m; światło latarek powinno być widoczne z odległości co najmniej 150 m.\",\n",
    "    \"Art. 12. 7. Zabrania się: ruchu po jezdni kolumny pieszych w czasie mgły; zakaz ten nie dotyczy kolumny wojskowej lub policyjnej; ruchu po jezdni kolumny pieszych w wieku do 10 lat w warunkach niedostatecznej widoczności; prowadzenia po jezdni kolumny pieszych przez osobę w wieku poniżej 18 lat.\",\n",
    "    \"Art. 13. 1. Pieszy, przechodząc przez jezdnię lub torowisko, jest obowiązany zachować szczególną ostrożność oraz, z zastrzeżeniem ust. 2 i 3, korzystać z przejścia dla pieszych. Pieszy znajdujący się na tym przejściu ma pierwszeństwo przed pojazdem.\",\n",
    "    \"Art. 13. 2. Przechodzenie przez jezdnię poza przejściem dla pieszych jest dozwolone, gdy odległość od przejścia przekracza 100 m. Jeżeli jednak skrzyżowanie znajduje się w odległości mniejszej niż 100 m od wyznaczonego przejścia, przechodzenie jest dozwolone również na tym skrzyżowaniu.\",\n",
    "    \"Art. 13. 3. Przechodzenie przez jezdnię poza przejściem dla pieszych, o którym mowa w ust. 2, jest dozwolone tylko pod warunkiem, że nie spowoduje zagrożenia bezpieczeństwa ruchu lub utrudnienia ruchu pojazdów. Pieszy jest obowiązany ustąpić pierwszeństwa pojazdom i do przeciwległej krawędzi jezdni iść drogą najkrótszą, prostopadle do osi jezdni.\",\n",
    "    \"Art. 13. 4. Jeżeli na drodze znajduje się przejście nadziemne lub podziemne dla pieszych, pieszy jest obowiązany korzystać z niego, z zastrzeżeniem ust. 2 i 3.\",\n",
    "    \"Art. 13. 5. Na obszarze zabudowanym, na drodze dwujezdniowej lub po której kursują tramwaje po torowisku wyodrębnionym z jezdni, pieszy przechodząc przez jezdnię lub torowisko jest obowiązany korzystać tylko z przejścia dla pieszych.\",\n",
    "    \"Art. 13. 6. Przechodzenie przez torowisko wyodrębnione z jezdni jest dozwolone tylko w miejscu do tego przeznaczonym.\",\n",
    "    \"Art. 13. 7. Jeżeli wysepka dla pasażerów na przystanku komunikacji publicznej łączy się z przejściem dla pieszych, przechodzenie do i z przystanku jest dozwolone tylko po tym przejściu.\",\n",
    "    \"Art. 13. 8. Jeżeli przejście dla pieszych wyznaczone jest na drodze dwujezdniowej, przejście na każdej jezdni uważa się za przejście odrębne. Przepis ten stosuje się odpowiednio do przejścia dla pieszych w miejscu, w którym ruch pojazdów jest rozdzielony wysepką lub za pomocą innych urządzeń na jezdni.\",\n",
    "    \"Art. 14. Zabrania się: wchodzenia na jezdnię: bezpośrednio przed jadący pojazd, w tym również na przejściu dla pieszych, spoza pojazdu lub innej przeszkody ograniczającej widoczność drogi; przechodzenia przez jezdnię w miejscu o ograniczonej widoczności drogi; zwalniania kroku lub zatrzymywania się bez uzasadnionej potrzeby podczas przechodzenia przez jezdnię lub torowisko; przebiegania przez jezdnię; chodzenia po torowisku; wchodzenia na torowisko, gdy zapory lub półzapory są opuszczone lub opuszczanie ich rozpoczęto; przechodzenia przez jezdnię w miejscu, w którym urządzenie zabezpieczające lub przeszkoda oddzielają drogę dla pieszych albo chodnik od jezdni, bez względu na to, po której stronie jezdni one się znajdują.\"\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgebase_2 = [\n",
    "    \"Smartfon Apple iPhone 15 Pro z ekranem OLED 6.1 cala, procesorem A17 Pro i aparatem 48 MP.\",\n",
    "    \"Smartfon Samsung Galaxy S24 Ultra z wyświetlaczem 6.8 cala QHD+ i zoomem optycznym 10x.\",\n",
    "    \"Smartfon Xiaomi 14 z szybkim ładowaniem 120W i baterią 5000 mAh.\",\n",
    "    \"Smartfon Google Pixel 8 Pro z czystym Androidem i aparatem fotograficznym wspieranym AI.\",\n",
    "    \"Smartfon OnePlus 12 z ekranem AMOLED 120Hz i ładowaniem bezprzewodowym 50W.\",\n",
    "    \"Laptop Apple MacBook Air M3 13 cali, 8 GB RAM i dysk SSD 256 GB.\",\n",
    "    \"Laptop Dell XPS 13 z procesorem Intel Core i7, 16 GB RAM i ekranem InfinityEdge.\",\n",
    "    \"Laptop Lenovo ThinkPad X1 Carbon 11th Gen z ekranem 14 cali i systemem Windows 11 Pro.\",\n",
    "    \"Laptop HP Spectre x360 14 – ultrabook z ekranem dotykowym OLED i procesorem i7.\",\n",
    "    \"Laptop ASUS ROG Zephyrus G14 z kartą graficzną RTX 4060 i procesorem AMD Ryzen 9.\",\n",
    "    \"Telewizor LG OLED C4 55 cali 4K UHD z systemem webOS i Dolby Vision.\",\n",
    "    \"Telewizor Samsung QLED 65 cali Neo QLED z procesorem Quantum 4K.\",\n",
    "    \"Telewizor Sony Bravia XR 75 cali z technologią Cognitive Processor XR i Google TV.\",\n",
    "    \"Telewizor Philips Ambilight 55 cali z podświetleniem LED i obsługą HDR10+.\",\n",
    "    \"Telewizor TCL 43 cali 4K Smart TV z systemem Google TV i Wi-Fi.\",\n",
    "    \"Słuchawki Apple AirPods Pro 2 z aktywną redukcją szumów i etui MagSafe.\",\n",
    "    \"Słuchawki Sony WH-1000XM5 z redukcją hałasu i czasem pracy 30 godzin.\",\n",
    "    \"Słuchawki Bose QuietComfort Ultra z dźwiękiem przestrzennym i Bluetooth 5.3.\",\n",
    "    \"Słuchawki JBL Tune 770NC z mikrofonem i trybem ambient.\",\n",
    "    \"Słuchawki gamingowe SteelSeries Arctis Nova 7 Wireless z dźwiękiem 3D i mikrofonem.\",\n",
    "    \"Smartwatch Apple Watch Series 10 z ekranem Retina Always-On i czujnikiem EKG.\",\n",
    "    \"Smartwatch Samsung Galaxy Watch6 Classic z ramką obrotową i monitorowaniem snu.\",\n",
    "    \"Smartwatch Garmin Fenix 8 z GPS, pulsoksymetrem i trybem treningowym.\",\n",
    "    \"Smartwatch Huawei Watch GT 5 z baterią na 10 dni i pomiarem tętna.\",\n",
    "    \"Smartwatch Amazfit GTR 4 z obsługą rozmów Bluetooth i GPS.\",\n",
    "    \"Monitor Dell UltraSharp 27 cali 4K UHD z panelem IPS i pokryciem sRGB 99%.\",\n",
    "    \"Monitor LG UltraGear 32 cali QHD 165Hz dla graczy.\",\n",
    "    \"Monitor Samsung Odyssey G9 49 cali z zakrzywionym ekranem QLED 240Hz.\",\n",
    "    \"Monitor ASUS ProArt 27 cali 4K dla grafików i projektantów.\",\n",
    "    \"Monitor Philips 24 cali Full HD z cienkimi ramkami i trybem LowBlue.\",\n",
    "    \"Aparat Sony Alpha 7 IV bezlusterkowiec z matrycą 33 MP i nagrywaniem 4K.\",\n",
    "    \"Aparat Canon EOS R6 Mark II z szybkim autofocusem i stabilizacją obrazu.\",\n",
    "    \"Aparat Nikon Z6 II z matrycą 24.5 MP i dwoma slotami na karty pamięci.\",\n",
    "    \"Aparat Fujifilm X-T5 z matrycą APS-C 40 MP i trybem filmowania 6.2K.\",\n",
    "    \"Aparat Panasonic Lumix GH6 z matrycą Micro Four Thirds i 10-bitowym zapisem.\",\n",
    "    \"Odkurzacz Dyson V15 Detect z laserem wykrywającym kurz i filtrem HEPA.\",\n",
    "    \"Odkurzacz Xiaomi Mi Vacuum Cleaner G10 z silnikiem 125 000 rpm i ekranem LCD.\",\n",
    "    \"Odkurzacz robot iRobot Roomba j7+ z automatycznym opróżnianiem pojemnika.\",\n",
    "    \"Odkurzacz Samsung Jet 90 Complete z baterią 60 min i stojakiem do ładowania.\",\n",
    "    \"Odkurzacz Philips SpeedPro Max Aqua z funkcją mopowania i LED.\",\n",
    "    \"Lodówka Samsung Bespoke RB38 z podwójnym obiegiem chłodzenia i wyświetlaczem.\",\n",
    "    \"Lodówka LG InstaView Door-in-Door z szybą dotykową i Wi-Fi.\",\n",
    "    \"Lodówka Bosch Serie 6 No Frost z pojemnością 366 litrów i klasą A++.\",\n",
    "    \"Lodówka Whirlpool W7 z funkcją Total No Frost i trybem Eco.\",\n",
    "    \"Lodówka Beko HarvestFresh z technologią światła imitującego cykl dobowy.\",\n",
    "    \"Pralka Samsung AddWash 8 kg z funkcją EcoBubble i panelem AI Control.\",\n",
    "    \"Pralka LG AI DD 9 kg z automatycznym doborem ruchów piorących.\",\n",
    "    \"Pralka Bosch Serie 6 VarioPerfect z silnikiem EcoSilence Drive.\",\n",
    "    \"Pralka Electrolux PerfectCare 700 z funkcją SteamCare i czujnikiem wagowym.\",\n",
    "    \"Pralka Whirlpool FreshCare+ z parą i programem szybkim 30 minut.\",\n",
    "    \"Konsola Sony PlayStation 5 Slim z dyskiem SSD 1 TB i kontrolerem DualSense.\",\n",
    "    \"Konsola Microsoft Xbox Series X z obsługą gier 4K i dyskiem 1 TB SSD.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgebase = knowledgebase_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare connection with OpenAI\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=APIKey,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate embeddings \n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************S90A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Create a database \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m embeddings = [\u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m knowledgebase]\n\u001b[32m      5\u001b[39m df = pd.DataFrame({\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mText\u001b[39m\u001b[33m'\u001b[39m: knowledgebase,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mVector\u001b[39m\u001b[33m'\u001b[39m: embeddings\n\u001b[32m      8\u001b[39m })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_embedding\u001b[39m\u001b[34m(text, model)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding\u001b[39m(text, model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-ada-002\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      3\u001b[39m    text = text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m.data[\u001b[32m0\u001b[39m].embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/resources/embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************S90A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "#Create a database \n",
    "import pandas as pd\n",
    "embeddings = [get_embedding(text) for text in knowledgebase]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Text': knowledgebase,\n",
    "    'Vector': embeddings\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"ruch pieszych po ulicy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2_1 = \"telefon z dobrym aparatem\"\n",
    "query_2_2 = \"pralka z funkcją pary\"\n",
    "query_2_3 = \"laptop do gier\"\n",
    "query_2_4 = \"telewizor OLED z dużym ekranem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = get_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, euclidean\n",
    "df['Cosine_Similarity'] = df['Vector'].apply(lambda x: cosine(x, query_vector))\n",
    "df[\"Euclidean_Distance\"] = df[\"Vector\"].apply(lambda x: euclidean(x, query_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Cosine_Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = df.nsmallest(3, 'Cosine_Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Kosinusowa ---\")\n",
    "print(df.nsmallest(3, \"Cosine_Distance\")[\"Text\"])\n",
    "print(\"\\n--- Euklidesowa ---\")\n",
    "print(df.nsmallest(3, \"Euclidean_Distance\")[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rezultat to:')\n",
    "for reg in selected_rows['Text']:\n",
    "    print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#  Funkcje odległości\n",
    "# ============================================\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    return 1 - np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return norm(np.array(a) - np.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#  Wyszukiwanie najbardziej podobnych wpisów\n",
    "# ============================================\n",
    "\n",
    "def search_knowledgebase(query, top_x=5, distance=\"cosine\"):\n",
    "    query_vector = get_embedding(query)\n",
    "    if distance == \"cosine\":\n",
    "        df[\"Distance\"] = df[\"Vector\"].apply(lambda x: cosine_distance(x, query_vector))\n",
    "    else:\n",
    "        df[\"Distance\"] = df[\"Vector\"].apply(lambda x: euclidean_distance(x, query_vector))\n",
    "    return df.nsmallest(top_x, \"Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#  Generowanie odpowiedzi na podstawie kontekstu\n",
    "# ============================================\n",
    "\n",
    "def generate_answer(query, context_texts):\n",
    "    context = \"\\n\".join(context_texts)\n",
    "    prompt = f\"\"\"\n",
    "Jesteś asystentem sklepu z elektroniką.\n",
    "Odpowiedz na pytanie klienta na podstawie poniższej wiedzy:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pytanie: {query}\n",
    "\n",
    "Odpowiedz pełnym zdaniem, po polsku, w sposób pomocny i naturalny.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ============================================\n",
    "#  Główna logika – zapytanie użytkownika\n",
    "# ============================================\n",
    "\n",
    "query = input(\"Zadaj pytanie: \")\n",
    "\n",
    "# Dynamiczny dobór x – więcej kontekstu dla krótkich pytań\n",
    "x = 5 if len(query) < 50 else 3\n",
    "\n",
    "top_matches = search_knowledgebase(query, top_x=x, distance=\"cosine\")\n",
    "\n",
    "print(\"\\n--- Najbardziej dopasowane fragmenty ---\")\n",
    "for i, t in enumerate(top_matches[\"Text\"].tolist(), start=1):\n",
    "    print(f\"{i}. {t}\")\n",
    "\n",
    "answer = generate_answer(query, top_matches[\"Text\"].tolist())\n",
    "\n",
    "print(\"\\n Odpowiedź asystenta:\\n\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
